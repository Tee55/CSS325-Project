{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 11:10:13.620503: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 11:10:13.620556: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 11:10:13.620597: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 11:10:13.627056: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to /home/tee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(tp, tn, fp, fn):\n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def precision_function(tp, fp):\n",
    "    precision = tp / (tp+fp)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall_function(tp, fn):\n",
    "    recall = tp / (tp+fn)\n",
    "    return recall\n",
    "\n",
    "def confusion_matrix(truth, predicted):\n",
    "\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    for true, pred in zip(truth, predicted):\n",
    "\n",
    "        if true == '1' or 1:\n",
    "            if pred == true:\n",
    "                true_positive += 1\n",
    "            elif pred != true:\n",
    "                false_negative += 1\n",
    "\n",
    "        elif true == '0' or 1:\n",
    "            if pred == true:\n",
    "                true_negative += 1\n",
    "            elif pred != true:\n",
    "                false_positive += 1\n",
    "\n",
    "    accuracy = accuracy_function(true_positive, true_negative, false_positive, false_negative)\n",
    "    precision = precision_function(true_positive, false_positive)\n",
    "    recall = recall_function(true_positive, false_negative)\n",
    "\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "def build_cnn():\n",
    "\n",
    "    model = tf.keras.Sequential(name=\"CNN\")\n",
    "\n",
    "    model.add(tf.keras.layers.Input(shape=(4096, 1)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=4, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence Label\n",
      "0                  \" or pg_sleep  (  __TIME__  )  --     1\n",
      "2   AND 1  =  utl_inaddr.get_host_address   (    ...     1\n",
      "3   select * from users where id  =  '1' or @ @1 ...     1\n",
      "4   select * from users where id  =  1 or 1#\"  ( ...     1\n",
      "5   select name from syscolumns where id   =     ...     1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/SQLiV3.csv\")\n",
    "\n",
    "# Drop duplicate row\n",
    "df = df.drop_duplicates('Sentence')\n",
    "\n",
    "df = df.drop('Unnamed: 2', axis=1, errors='ignore')\n",
    "df = df.drop('Unnamed: 3', axis=1, errors='ignore')\n",
    "\n",
    "# Drop row with Nan\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "# Drop row with incorrect label\n",
    "df = df[(df['Label'] == '0') | (df['Label'] == '1')]\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Reset index\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "y = np.array([int(i) for i in df['Label'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=4096, ngram_range=(2, 2))\n",
    "#vectorizer = TfidfVectorizer(min_df=2, max_df=0.7, stop_words='english')\n",
    "\n",
    "count_matrix = vectorizer.fit_transform(df['Sentence']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(count_matrix, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (24472, 4096)\n",
      "Test shape: (6118, 4096)\n"
     ]
    }
   ],
   "source": [
    "# (sentence_index, feature_index) count\n",
    "print(\"Train shape: {}\".format(X_train.shape))\n",
    "print(\"Test shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not SQLi       0.92      0.99      0.95      3828\n",
      "        SQLi       0.98      0.85      0.91      2290\n",
      "\n",
      "    accuracy                           0.94      6118\n",
      "   macro avg       0.95      0.92      0.93      6118\n",
      "weighted avg       0.94      0.94      0.94      6118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\"\"\" accuracy, precision, recall = confusion_matrix(y_test, y_pred)\n",
    "print(\"=================Logistic Regression Result=================\")\n",
    "print(\"Accuracy : {:.4f}\".format(accuracy))\n",
    "print(\"Precision : {:.4f}\".format(precision))\n",
    "print(\"Recall : {:.4f}\".format(recall)) \"\"\"\n",
    "\n",
    "target_names = ['Not SQLi', 'SQLi']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not SQLi       0.93      0.98      0.95      3828\n",
      "        SQLi       0.97      0.87      0.91      2290\n",
      "\n",
      "    accuracy                           0.94      6118\n",
      "   macro avg       0.95      0.93      0.93      6118\n",
      "weighted avg       0.94      0.94      0.94      6118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\"\"\" accuracy, precision, recall = confusion_matrix(y_test, y_pred)\n",
    "print(\"=================KNN Result=================\")\n",
    "print(\"Accuracy : {:.4f}\".format(accuracy))\n",
    "print(\"Precision : {:.4f}\".format(precision))\n",
    "print(\"Recall : {:.4f}\".format(recall)) \"\"\"\n",
    "\n",
    "target_names = ['Not SQLi', 'SQLi']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolutional Neural Networks Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (24472, 4096, 1)\n",
      "Test shape: (6118, 4096, 1)\n",
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 4093, 64)          320       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 2046, 64)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2043, 128)         32896     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 1021, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 130688)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16728192  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16761537 (63.94 MB)\n",
      "Trainable params: 16761537 (63.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 11:10:37.703690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:37.711080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:37.711113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:37.713857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:37.713882: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:37.713898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:38.031932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:38.031975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:38.031983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-19 11:10:38.032007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-19 11:10:38.032024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6109 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 11:10:38.737258: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 801898496 exceeds 10% of free system memory.\n",
      "2023-11-19 11:10:38.976421: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 801898496 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 11:10:39.868941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-19 11:10:40.497925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4d1c0c14d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-19 11:10:40.498005: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2023-11-19 11:10:40.502896: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-19 11:10:40.574033: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2448/2448 [==============================] - 29s 11ms/step - loss: 0.1739 - accuracy: 0.9391 - val_loss: 0.1429 - val_accuracy: 0.9518\n",
      "Epoch 2/5\n",
      "2448/2448 [==============================] - 28s 11ms/step - loss: 0.1468 - accuracy: 0.9471 - val_loss: 0.1378 - val_accuracy: 0.9524\n",
      "Epoch 3/5\n",
      "2448/2448 [==============================] - 28s 11ms/step - loss: 0.1441 - accuracy: 0.9476 - val_loss: 0.1348 - val_accuracy: 0.9526\n",
      "Epoch 4/5\n",
      "2448/2448 [==============================] - 28s 12ms/step - loss: 0.1431 - accuracy: 0.9481 - val_loss: 0.1348 - val_accuracy: 0.9529\n",
      "Epoch 5/5\n",
      "2448/2448 [==============================] - 28s 12ms/step - loss: 0.1430 - accuracy: 0.9481 - val_loss: 0.1356 - val_accuracy: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f4e8d726fe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 4096, 1)\n",
    "X_test = X_test.reshape(-1, 4096, 1)\n",
    "\n",
    "# CNN shape\n",
    "print(\"Train shape: {}\".format(X_train.shape))\n",
    "print(\"Test shape: {}\".format(X_test.shape))\n",
    "\n",
    "cnn = build_cnn()\n",
    "cnn.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4), metrics=['accuracy'])\n",
    "cnn.fit(X_train, y_train, batch_size=10, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not SQLi       0.93      1.00      0.96      3828\n",
      "        SQLi       1.00      0.87      0.93      2290\n",
      "\n",
      "    accuracy                           0.95      6118\n",
      "   macro avg       0.96      0.94      0.95      6118\n",
      "weighted avg       0.96      0.95      0.95      6118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "\n",
    "# Turn sigmoid result to 0 or 1\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "\"\"\" accuracy, precision, recall = confusion_matrix(y_test, y_pred)\n",
    "print(\"=================CNN Result=================\")\n",
    "print(\"Accuracy : {:.4f}\".format(accuracy))\n",
    "print(\"Precision : {:.4f}\".format(precision))\n",
    "print(\"Recall : {:.4f}\".format(recall)) \"\"\"\n",
    "\n",
    "target_names = ['Not SQLi', 'SQLi']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
